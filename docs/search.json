[
  {
    "objectID": "Modeling.html",
    "href": "Modeling.html",
    "title": "Project 3 Modeling",
    "section": "",
    "text": "After doing an exploratory data analysis on four variables in relation to diabetic outcomes, I found I was most interested to see how Sex, Income and Education performed as predictors of Diabetes diagnosis. These were the four variables that, at a glance, showed possibly some effect of amount of diabetes. I also find it interesting that these predictors are not comorbidities, they are rather biological (sex) or socio-economic (income and education) categories that people fall into. This means that without having extra medical measurements done, providers could be aware of how the risk differs between patients, and perhaps patients would consent to early screenings, etc. Let’s see how good these variables are at predicting a diabetic diagnosis!\n\n\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(knitr)\nlibrary(tidymodels)\nlibrary(tree)\nlibrary(dplyr)\nlibrary(ranger)\n\n\n\n\n\n#read in diabetes data from folder\ndiabetes_data &lt;- read_csv(\"diabetes_data.csv\")\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n#now for chosen variables change each to factor and give meaningful labels for the levels\ndiabetes_data_reduced &lt;- read_csv(\"diabetes_data.csv\")%&gt;% \n  mutate(Diabetes_binary = factor(Diabetes_binary, levels= c(0,1), labels=c(\"No Diabetes\", \"Diabetes\")),\n         Sex = factor(Sex, levels= c(0,1), labels = c(\"Female\", \"Male\")), \n         # info sheet says 5 year increments\n         Age = factor(Age, levels = c(1,2,3,4,5,6,7,8,9,10,11,12,13), labels = c(\"18to24\", \"25to29\", \"30to34\", \"35to39\", \"40to44\", \"45to49\", \"50to54\", \"55to59\", \"60to64\", \"65to69\", \"70to74\", \"75to79\", \"80plus\")),\n         Education= factor(Education, levels= c(1,2,3,4,5,6), labels=c(\"Never attended or only kindergarten\",\"Elementary\",\"Some high school\", \"High school graduate\",\"Some college or technical school\",\"College graduate\")), \n         Income = factor(Income, levels = c(1,2,3,4,5,6,7,8), labels = c(\"&lt; $10,000\",\"&lt; $15,000\",\"&lt; $20,000\",\"&lt; $25,000\", \"&lt; $35,000\",\"&lt; $50,000\",\"&lt; $75,000\",\"$75,000+\")))%&gt;%\n  #select only relevant variables to work with smaller data set\n  select(Diabetes_binary, Age, Sex, Education, Income)\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\n#split data into testing and training set with prop 70/30:\nset.seed(415)\ndiab_split &lt;- initial_split(diabetes_data_reduced, prop = 0.7)\n\ntest &lt;- testing(diab_split)\n  \ntrain &lt;- training(diab_split)"
  },
  {
    "objectID": "Modeling.html#introduction",
    "href": "Modeling.html#introduction",
    "title": "Project 3 Modeling",
    "section": "",
    "text": "After doing an exploratory data analysis on four variables in relation to diabetic outcomes, I found I was most interested to see how Sex, Income and Education performed as predictors of Diabetes diagnosis. These were the four variables that, at a glance, showed possibly some effect of amount of diabetes. I also find it interesting that these predictors are not comorbidities, they are rather biological (sex) or socio-economic (income and education) categories that people fall into. This means that without having extra medical measurements done, providers could be aware of how the risk differs between patients, and perhaps patients would consent to early screenings, etc. Let’s see how good these variables are at predicting a diabetic diagnosis!\n\n\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(knitr)\nlibrary(tidymodels)\nlibrary(tree)\nlibrary(dplyr)\nlibrary(ranger)\n\n\n\n\n\n#read in diabetes data from folder\ndiabetes_data &lt;- read_csv(\"diabetes_data.csv\")\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n#now for chosen variables change each to factor and give meaningful labels for the levels\ndiabetes_data_reduced &lt;- read_csv(\"diabetes_data.csv\")%&gt;% \n  mutate(Diabetes_binary = factor(Diabetes_binary, levels= c(0,1), labels=c(\"No Diabetes\", \"Diabetes\")),\n         Sex = factor(Sex, levels= c(0,1), labels = c(\"Female\", \"Male\")), \n         # info sheet says 5 year increments\n         Age = factor(Age, levels = c(1,2,3,4,5,6,7,8,9,10,11,12,13), labels = c(\"18to24\", \"25to29\", \"30to34\", \"35to39\", \"40to44\", \"45to49\", \"50to54\", \"55to59\", \"60to64\", \"65to69\", \"70to74\", \"75to79\", \"80plus\")),\n         Education= factor(Education, levels= c(1,2,3,4,5,6), labels=c(\"Never attended or only kindergarten\",\"Elementary\",\"Some high school\", \"High school graduate\",\"Some college or technical school\",\"College graduate\")), \n         Income = factor(Income, levels = c(1,2,3,4,5,6,7,8), labels = c(\"&lt; $10,000\",\"&lt; $15,000\",\"&lt; $20,000\",\"&lt; $25,000\", \"&lt; $35,000\",\"&lt; $50,000\",\"&lt; $75,000\",\"$75,000+\")))%&gt;%\n  #select only relevant variables to work with smaller data set\n  select(Diabetes_binary, Age, Sex, Education, Income)\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\n#split data into testing and training set with prop 70/30:\nset.seed(415)\ndiab_split &lt;- initial_split(diabetes_data_reduced, prop = 0.7)\n\ntest &lt;- testing(diab_split)\n  \ntrain &lt;- training(diab_split)"
  },
  {
    "objectID": "Modeling.html#logistic-regression-models",
    "href": "Modeling.html#logistic-regression-models",
    "title": "Project 3 Modeling",
    "section": "Logistic Regression Models:",
    "text": "Logistic Regression Models:\nA logistic regression model is ___.\n\nRecipes for LR models:\n\nLR1_rec &lt;- recipe(Diabetes_binary ~ Sex+ Income+ Education, data = train)%&gt;%\n  step_dummy(all_nominal_predictors())\n\nLR2_rec  &lt;- recipe(Diabetes_binary ~ Sex + Income, data = train) %&gt;%\n  step_dummy(all_nominal_predictors())\n\nLR3_rec &lt;- recipe(Diabetes_binary ~ Income + Education, data = train) %&gt;%\n  step_dummy(all_nominal_predictors())\n\n\n\nModel specs:\n\n#logistic regression model specs: \n\nLR_spec &lt;- logistic_reg() %&gt;%\n  set_engine(\"glm\")\n\n\n\nWorkflows:\n\nLR1_wkf &lt;- workflow() %&gt;%\n add_recipe(LR1_rec) %&gt;%\n add_model(LR_spec)\nLR2_wkf &lt;- workflow() %&gt;%\n add_recipe(LR2_rec) %&gt;%\n add_model(LR_spec)\nLR3_wkf &lt;- workflow() %&gt;%\n add_recipe(LR3_rec) %&gt;%\n add_model(LR_spec)\n\n\n\nCV 5-fold\n\ndiab_cv_folds &lt;- vfold_cv(train, v= 5)\n\n\n\nFit to our CV folds:\n\nLR1_fit &lt;- LR1_wkf %&gt;%\n fit_resamples(diab_cv_folds, metrics = metric_set(accuracy, mn_log_loss))\nLR2_fit &lt;- LR2_wkf %&gt;%\n fit_resamples(diab_cv_folds, metrics = metric_set(accuracy, mn_log_loss))\nLR3_fit &lt;- LR3_wkf %&gt;%\n fit_resamples(diab_cv_folds, metrics = metric_set(accuracy, mn_log_loss))\n\n\n\nCollect metrics:\n\nrbind(LR1_fit %&gt;% collect_metrics(),\n LR2_fit %&gt;% collect_metrics(),\n LR3_fit %&gt;% collect_metrics()) %&gt;%\n mutate(Model = c(\"Model1\", \"Model1\", \"Model2\", \"Model2\", \"Model3\", \"Model3\")) %&gt;%\n select(Model, everything())\n\n# A tibble: 6 × 7\n  Model  .metric     .estimator  mean     n  std_err .config             \n  &lt;chr&gt;  &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;               \n1 Model1 accuracy    binary     0.861     5 0.000928 Preprocessor1_Model1\n2 Model1 mn_log_loss binary     0.388     5 0.00186  Preprocessor1_Model1\n3 Model2 accuracy    binary     0.861     5 0.000928 Preprocessor1_Model1\n4 Model2 mn_log_loss binary     0.389     5 0.00179  Preprocessor1_Model1\n5 Model3 accuracy    binary     0.861     5 0.000928 Preprocessor1_Model1\n6 Model3 mn_log_loss binary     0.389     5 0.00179  Preprocessor1_Model1\n\n\nThe best model is model 1 because it is showing the lowest log loss and also has a smaller standard error. It appears all of the models have similar accuracy so that didn’t help in the selection process.\n\n\nBest model test on test set:\n\nfinal_LRmodel&lt;- LR1_wkf |&gt;\n last_fit(diab_split, metrics = metric_set(accuracy, mn_log_loss)) |&gt;\n collect_metrics()\n\nfinal_LRmodel\n\n# A tibble: 2 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary         0.861 Preprocessor1_Model1\n2 mn_log_loss binary         0.387 Preprocessor1_Model1\n\n\nWe got our best model, model 1, from the LR models and tested it on the test set. On the test set our final LR model scored about an 86% accuracy and a log loss of 0.387.\nIn summary, the mean CV log-loss was 0.387, 0.389 and 0.389 for models 1,2, and 3 respectively. This means the best model at predicting diabetes outcomes with new data was model 1 which included the Sex, Education and Income predictors. We will keep this model and keep these variables in as predictors!"
  },
  {
    "objectID": "Modeling.html#classification-tree",
    "href": "Modeling.html#classification-tree",
    "title": "Project 3 Modeling",
    "section": "Classification Tree:",
    "text": "Classification Tree:\n\n#tree recipe \ntree_rec &lt;- recipe(Diabetes_binary ~ Sex + Income + Education, data = train) %&gt;%\n  step_dummy(all_nominal_predictors())\n\n#model spec\ntree_mod &lt;- decision_tree(\n  cost_complexity = tune(), \n  min_n = 20) %&gt;%\n  set_engine(\"rpart\") %&gt;%\n  set_mode(\"classification\")\n\n#tree workflow\ntree_wkf &lt;- workflow() %&gt;%\n  add_recipe(tree_rec) %&gt;% \n  add_model(tree_mod)\n\n# tree grid\ncp_grid &lt;- grid_regular(\n  cost_complexity(),\n  levels = 10)\n\n# tune grid with log‑loss as the metric\ntemp &lt;- tune_grid(\n  tree_wkf,\n  resamples = diab_cv_folds,\n  grid      = cp_grid,\n  metrics   = metric_set(mn_log_loss))\n\n# get best tree, slice top value\n\nbest_tree &lt;- temp %&gt;%\n  collect_metrics() %&gt;%\n  filter(.metric == \"mn_log_loss\") %&gt;%\n  arrange(mean) %&gt;%\n  slice(1)\n#show best tree\nbest_tree\n\n# A tibble: 1 × 7\n  cost_complexity .metric     .estimator  mean     n std_err .config            \n            &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;              \n1    0.0000000001 mn_log_loss binary     0.404     5 0.00169 Preprocessor1_Mode…\n\n#finalize workflow\nfinal_tree_wkf &lt;- finalize_workflow(tree_wkf, best_tree)\n\n#fit on full training set and evaluate on test set\ntree_last &lt;- last_fit(\n  final_tree_wkf,\n  diab_split,\n  metrics = metric_set(accuracy, mn_log_loss))\n\ntree_last %&gt;% collect_metrics()\n\n# A tibble: 2 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary         0.861 Preprocessor1_Model1\n2 mn_log_loss binary         0.403 Preprocessor1_Model1\n\n\nWith these results, it looks our accuracy remains similar to our best LR model; however, the log-loss is higher (0.4033) than the best LR model. We would not choose this model over the LR model 1 as it would give more confident predictions."
  },
  {
    "objectID": "Modeling.html#random-forest",
    "href": "Modeling.html#random-forest",
    "title": "Project 3 Modeling",
    "section": "Random Forest",
    "text": "Random Forest\n\n#random forest spec\nrf_spec &lt;- rand_forest(mtry = tune(), trees = 10) %&gt;%\n set_engine(\"ranger\") %&gt;%\n set_mode(\"classification\")\n\n#RF workflow \n\nrf_wkf &lt;- workflow() %&gt;%\n add_recipe(LR3_rec) %&gt;%\n add_model(rf_spec)\n \n\n#mtry grid from 1 to 3 because we have 3 predictors\nrf_grid &lt;- grid_regular(\n  mtry(range = c(1, 3)), \n  levels = 7)\n\n\n# fit to CV folds\n\nrf_fit &lt;- rf_wkf %&gt;%\n tune_grid(resamples = diab_cv_folds,\n grid = rf_grid,\n metrics = metric_set(accuracy, mn_log_loss))\n\n#look at log loss and sort\n\nrf_fit %&gt;%\n collect_metrics() %&gt;%\n filter(.metric == \"mn_log_loss\") %&gt;%\n arrange(mean)\n\n# A tibble: 3 × 7\n   mtry .metric     .estimator  mean     n std_err .config             \n  &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1     3 mn_log_loss binary     0.389     5 0.00180 Preprocessor1_Model3\n2     2 mn_log_loss binary     0.390     5 0.00190 Preprocessor1_Model2\n3     1 mn_log_loss binary     0.393     5 0.00195 Preprocessor1_Model1\n\n#get best tuning parameter\nrf_best_params &lt;- select_best(rf_fit, metric = \"mn_log_loss\")\nrf_best_params\n\n# A tibble: 1 × 2\n   mtry .config             \n  &lt;int&gt; &lt;chr&gt;               \n1     3 Preprocessor1_Model3\n\n#refit on whole traning set and test on testing set \nrf_final_wkf &lt;- rf_wkf %&gt;%\n finalize_workflow(rf_best_params)\n\nrf_final_fit &lt;- rf_final_wkf %&gt;%\n  last_fit(diab_split, metrics = metric_set(accuracy, mn_log_loss))"
  },
  {
    "objectID": "Modeling.html#final-model-selection",
    "href": "Modeling.html#final-model-selection",
    "title": "Project 3 Modeling",
    "section": "Final Model Selection",
    "text": "Final Model Selection\n\nfinal_LRmodel\n\n# A tibble: 2 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary         0.861 Preprocessor1_Model1\n2 mn_log_loss binary         0.387 Preprocessor1_Model1\n\ntree_last %&gt;% collect_metrics()\n\n# A tibble: 2 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary         0.861 Preprocessor1_Model1\n2 mn_log_loss binary         0.403 Preprocessor1_Model1\n\nrf_final_fit %&gt;% collect_metrics()\n\n# A tibble: 2 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary         0.861 Preprocessor1_Model1\n2 mn_log_loss binary         0.389 Preprocessor1_Model1\n\n\n\n#refit model without metrics for API\nfinal_fit_result &lt;- LR1_wkf |&gt;\n  last_fit(diab_split, metrics = metric_set(accuracy, mn_log_loss))\n\n#extract workflow and save rds\nfitted_workflow &lt;- extract_workflow(final_fit_result)\nsaveRDS(fitted_workflow, \"logRegFit_1.rds\")"
  },
  {
    "objectID": "EDA.html",
    "href": "EDA.html",
    "title": "Project 3 EDA",
    "section": "",
    "text": "Introduction section You should have an introduction section that • briefly describes the data and the variables you have to work with. • describes the purpose of your EDA and ultimate goal of modeling."
  },
  {
    "objectID": "EDA.html#introduction",
    "href": "EDA.html#introduction",
    "title": "Project 3 EDA",
    "section": "Introduction:",
    "text": "Introduction:\nDiabetes is a chronic illness that affects more than 36 million Americans and many more people world-wide. Diabetes is a condition where the body’s cells don’t respond to insulin properly, which leads to high blood sugar levels. It is currently understood to be irreversible and can result in a number of life altering comorbidities. Studies shows that most cases of type 2 diabetes can be prevented through lifestyle changes. As such, it is important to explore how certain health predictors are at predicting an outcome of diabetes because that would be a useful tool to predicting patient outcomes and guiding lifestyle interventions.\nWith a lot of research already having been done on this topic, certain health measurements are more obviously correlated with outcomes of diabetes (BMI, cholesterol, eating habits); so, for this EDA I wanted to explore some less obvious predictors of diabetes. I will be looking at Age, Sex, Education level and Income level as predictors of Diabetes diagnosis."
  },
  {
    "objectID": "EDA.html#libraries",
    "href": "EDA.html#libraries",
    "title": "Project 3 EDA",
    "section": "Libraries:",
    "text": "Libraries:\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(knitr)\nlibrary(scales)"
  },
  {
    "objectID": "EDA.html#data",
    "href": "EDA.html#data",
    "title": "Project 3 EDA",
    "section": "Data:",
    "text": "Data:\nImport data and change levels to meaningful names.\n\n#read in diabetes data from folder\ndiabetes_data &lt;- read_csv(\"diabetes_data.csv\")\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n#now for chosen variables change each to factor and give meaningful labels for the levels\ndiabetes_data_reduced &lt;- read_csv(\"diabetes_data.csv\")%&gt;% \n  mutate(Diabetes_binary = factor(Diabetes_binary, levels= c(0,1), labels=c(\"No Diabetes\", \"Diabetes\")),\n         Sex = factor(Sex, levels= c(0,1), labels = c(\"Female\", \"Male\")), \n         # info sheet says 5 year increments\n         Age = factor(Age, levels = c(1,2,3,4,5,6,7,8,9,10,11,12,13), labels = c(\"18to24\", \"25to29\", \"30to34\", \"35to39\", \"40to44\", \"45to49\", \"50to54\", \"55to59\", \"60to64\", \"65to69\", \"70to74\", \"75to79\", \"80plus\")),\n         Education= factor(Education, levels= c(1,2,3,4,5,6), labels=c(\"Never attended or only kindergarten\",\"Elementary\",\"Some high school\", \"High school graduate\",\"Some college or technical school\",\"College graduate\")), \n         Income = factor(Income, levels = c(1,2,3,4,5,6,7,8), labels = c(\"&lt; $10,000\",\"&lt; $15,000\",\"&lt; $20,000\",\"&lt; $25,000\", \"&lt; $35,000\",\"&lt; $50,000\",\"&lt; $75,000\",\"$75,000+\")))%&gt;%\n  #select only relevant variables to work with smaller data set\n  select(Diabetes_binary, Age, Sex, Education, Income)\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "EDA.html#univariate-analyses",
    "href": "EDA.html#univariate-analyses",
    "title": "Project 3 EDA",
    "section": "Univariate analyses:",
    "text": "Univariate analyses:\n\nHistograms for each variable:\n\n#age \n\na &lt;- ggplot(diabetes_data_reduced, aes(x=Age))\na + geom_bar(fill = \"hotpink\") + scale_y_continuous(labels = comma)\n\n\n\n\n\n\n\n#sex\n\ns &lt;- ggplot(diabetes_data_reduced, aes(x=Sex))\ns+ geom_bar(fill = \"hotpink\") + scale_y_continuous(labels = comma)\n\n\n\n\n\n\n\n#Education\ne &lt;- ggplot(diabetes_data_reduced, aes(x=Education))\ne+ geom_bar(fill = \"hotpink\") \n\n\n\n\n\n\n\n#Income\ni &lt;- ggplot(diabetes_data_reduced, aes(x=Income))\ni+ geom_bar(fill = \"hotpink\") \n\n\n\n\n\n\n\n\n\n\nNumeric summaries:\n\n#age table \nage_sum &lt;- diabetes_data_reduced %&gt;%\n  count(Age) %&gt;%\n  mutate(Percentage = 100*(n / sum(n)))\n\nkable(age_sum)\n\nWarning in attr(x, \"align\"): 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\n\nWarning in attr(x, \"format\"): 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\n\n\n\n\nAge\nn\nPercentage\n\n\n\n\n18to24\n5700\n2.246925\n\n\n25to29\n7598\n2.995112\n\n\n30to34\n11123\n4.384658\n\n\n35to39\n13823\n5.448991\n\n\n40to44\n16157\n6.369048\n\n\n45to49\n19819\n7.812599\n\n\n50to54\n26314\n10.372911\n\n\n55to59\n30832\n12.153895\n\n\n60to64\n33244\n13.104699\n\n\n65to69\n32194\n12.690791\n\n\n70to74\n23533\n9.276648\n\n\n75to79\n15980\n6.299275\n\n\n80plus\n17363\n6.844450\n\n\n\n\n#sex table \nsex_sum &lt;- diabetes_data_reduced %&gt;%\n  count(Sex) %&gt;%\n  mutate(Percentage = 100*(n / sum(n)))\n\nkable(sex_sum)\n\nWarning in attr(x, \"align\"): 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\nWarning in attr(x, \"align\"): 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\n\n\n\n\nSex\nn\nPercentage\n\n\n\n\nFemale\n141974\n55.96578\n\n\nMale\n111706\n44.03422\n\n\n\n\n#income table \nincome_sum &lt;- diabetes_data_reduced %&gt;%\n  count(Income) %&gt;%\n  mutate(Percentage = 100*(n / sum(n)))\n\nkable(income_sum)\n\nWarning in attr(x, \"align\"): 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\nWarning in attr(x, \"align\"): 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\n\n\n\n\nIncome\nn\nPercentage\n\n\n\n\n&lt; $10,000\n9811\n3.867471\n\n\n&lt; $15,000\n11783\n4.644828\n\n\n&lt; $20,000\n15994\n6.304793\n\n\n&lt; $25,000\n20135\n7.937165\n\n\n&lt; $35,000\n25883\n10.203012\n\n\n&lt; $50,000\n36470\n14.376380\n\n\n&lt; $75,000\n43219\n17.036818\n\n\n$75,000+\n90385\n35.629533\n\n\n\n\n#Education table \neducation_sum &lt;- diabetes_data_reduced %&gt;%\n  count(Education) %&gt;%\n  mutate(Percentage = 100*(n / sum(n)))\n\nkable(education_sum)\n\nWarning in attr(x, \"align\"): 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\nWarning in attr(x, \"align\"): 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\n\n\n\n\nEducation\nn\nPercentage\n\n\n\n\nNever attended or only kindergarten\n174\n0.0685904\n\n\nElementary\n4043\n1.5937401\n\n\nSome high school\n9478\n3.7362031\n\n\nHigh school graduate\n62750\n24.7358877\n\n\nSome college or technical school\n69910\n27.5583412\n\n\nCollege graduate\n107325\n42.3072375\n\n\n\n\n\nLooking at the variables on their own we can see that our data set contains values for age and sex that are relatively normally distributed, with there being about 10% more females in the survey. However, both education and income look pretty left skewed. This gives us a picture of our sample data. It seems more people answering the survey have pursued a college degree (~42%) and most people answering the survey make over $75,000 (~36%)."
  },
  {
    "objectID": "EDA.html#bivariate-exploration",
    "href": "EDA.html#bivariate-exploration",
    "title": "Project 3 EDA",
    "section": "Bivariate exploration:",
    "text": "Bivariate exploration:\nFilled bar plots of variable categories vs. Diabetes outcome:\n\n#age vs. diabetes\nggplot(diabetes_data_reduced, aes(x = Age, fill = Diabetes_binary)) +\n  geom_bar(stat = \"count\")\n\n\n\n\n\n\n\n#sex vs. diabetes\n\nggplot(diabetes_data_reduced, aes(x = Sex, fill = Diabetes_binary)) +\n  geom_bar(stat = \"count\") + scale_y_continuous(labels = comma)\n\n\n\n\n\n\n\n#education vs. diabetes\n\nggplot(diabetes_data_reduced, aes(x = Education, fill = Diabetes_binary)) +\n  geom_bar(stat = \"count\")\n\n\n\n\n\n\n\n#income vs. diabetes\n\nggplot(diabetes_data_reduced, aes(x = Income, fill = Diabetes_binary)) +\n  geom_bar(stat = \"count\")\n\n\n\n\n\n\n\n\n\nBivariate Numerical Summaries:\n\n#age vs. diabetes\nage_v_diab &lt;- diabetes_data_reduced %&gt;% \n  count(Age, Diabetes_binary) %&gt;%\n  group_by(Age)%&gt;%\n  mutate(Percentage = 100*(n/sum(n)))%&gt;%\n  ungroup()\n\nkable(age_v_diab)\n\nWarning in attr(x, \"align\"): 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\n\nWarning in attr(x, \"format\"): 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\n\n\n\n\nAge\nDiabetes_binary\nn\nPercentage\n\n\n\n\n18to24\nNo Diabetes\n5622\n98.631579\n\n\n18to24\nDiabetes\n78\n1.368421\n\n\n25to29\nNo Diabetes\n7458\n98.157410\n\n\n25to29\nDiabetes\n140\n1.842590\n\n\n30to34\nNo Diabetes\n10809\n97.177021\n\n\n30to34\nDiabetes\n314\n2.822979\n\n\n35to39\nNo Diabetes\n13197\n95.471316\n\n\n35to39\nDiabetes\n626\n4.528684\n\n\n40to44\nNo Diabetes\n15106\n93.495080\n\n\n40to44\nDiabetes\n1051\n6.504920\n\n\n45to49\nNo Diabetes\n18077\n91.210455\n\n\n45to49\nDiabetes\n1742\n8.789545\n\n\n50to54\nNo Diabetes\n23226\n88.264802\n\n\n50to54\nDiabetes\n3088\n11.735198\n\n\n55to59\nNo Diabetes\n26569\n86.173456\n\n\n55to59\nDiabetes\n4263\n13.826544\n\n\n60to64\nNo Diabetes\n27511\n82.754783\n\n\n60to64\nDiabetes\n5733\n17.245217\n\n\n65to69\nNo Diabetes\n25636\n79.629745\n\n\n65to69\nDiabetes\n6558\n20.370255\n\n\n70to74\nNo Diabetes\n18392\n78.154082\n\n\n70to74\nDiabetes\n5141\n21.845918\n\n\n75to79\nNo Diabetes\n12577\n78.704631\n\n\n75to79\nDiabetes\n3403\n21.295369\n\n\n80plus\nNo Diabetes\n14154\n81.518171\n\n\n80plus\nDiabetes\n3209\n18.481829\n\n\n\n\n#sex vs. diabetes\nsex_v_diab &lt;- diabetes_data_reduced %&gt;% \n  count(Sex, Diabetes_binary) %&gt;%\n  group_by(Sex)%&gt;%\n  mutate(Percentage = 100*(n/sum(n)))%&gt;%\n  ungroup()\n\nkable(sex_v_diab)\n\nWarning in attr(x, \"align\"): 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\nWarning in attr(x, \"align\"): 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\n\n\n\n\nSex\nDiabetes_binary\nn\nPercentage\n\n\n\n\nFemale\nNo Diabetes\n123563\n87.03213\n\n\nFemale\nDiabetes\n18411\n12.96787\n\n\nMale\nNo Diabetes\n94771\n84.83967\n\n\nMale\nDiabetes\n16935\n15.16033\n\n\n\n\n#income vs. diabetes\nincome_v_diab &lt;- diabetes_data_reduced %&gt;% \n  count(Income, Diabetes_binary) %&gt;%\n  group_by(Income)%&gt;%\n  mutate(Percentage = 100*(n/sum(n)))%&gt;%\n  ungroup()\n\nkable(income_v_diab)\n\nWarning in attr(x, \"align\"): 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\nWarning in attr(x, \"align\"): 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\n\n\n\n\nIncome\nDiabetes_binary\nn\nPercentage\n\n\n\n\n&lt; $10,000\nNo Diabetes\n7428\n75.710937\n\n\n&lt; $10,000\nDiabetes\n2383\n24.289063\n\n\n&lt; $15,000\nNo Diabetes\n8697\n73.809726\n\n\n&lt; $15,000\nDiabetes\n3086\n26.190274\n\n\n&lt; $20,000\nNo Diabetes\n12426\n77.691634\n\n\n&lt; $20,000\nDiabetes\n3568\n22.308366\n\n\n&lt; $25,000\nNo Diabetes\n16081\n79.865905\n\n\n&lt; $25,000\nDiabetes\n4054\n20.134095\n\n\n&lt; $35,000\nNo Diabetes\n21379\n82.598617\n\n\n&lt; $35,000\nDiabetes\n4504\n17.401383\n\n\n&lt; $50,000\nNo Diabetes\n31179\n85.492185\n\n\n&lt; $50,000\nDiabetes\n5291\n14.507815\n\n\n&lt; $75,000\nNo Diabetes\n37954\n87.817858\n\n\n&lt; $75,000\nDiabetes\n5265\n12.182142\n\n\n$75,000+\nNo Diabetes\n83190\n92.039608\n\n\n$75,000+\nDiabetes\n7195\n7.960392\n\n\n\n\n#education vs. diabetes\neducation_v_diab &lt;- diabetes_data_reduced %&gt;% \n  count(Education, Diabetes_binary) %&gt;%\n  group_by(Education)%&gt;%\n  mutate(Percentage = 100*(n/sum(n)))%&gt;%\n  ungroup()\n\nkable(education_v_diab)\n\nWarning in attr(x, \"align\"): 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\nWarning in attr(x, \"align\"): 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\n\n\n\n\n\n\n\n\n\n\nEducation\nDiabetes_binary\nn\nPercentage\n\n\n\n\nNever attended or only kindergarten\nNo Diabetes\n127\n72.988506\n\n\nNever attended or only kindergarten\nDiabetes\n47\n27.011494\n\n\nElementary\nNo Diabetes\n2860\n70.739550\n\n\nElementary\nDiabetes\n1183\n29.260450\n\n\nSome high school\nNo Diabetes\n7182\n75.775480\n\n\nSome high school\nDiabetes\n2296\n24.224520\n\n\nHigh school graduate\nNo Diabetes\n51684\n82.364940\n\n\nHigh school graduate\nDiabetes\n11066\n17.635060\n\n\nSome college or technical school\nNo Diabetes\n59556\n85.189529\n\n\nSome college or technical school\nDiabetes\n10354\n14.810471\n\n\nCollege graduate\nNo Diabetes\n96925\n90.309807\n\n\nCollege graduate\nDiabetes\n10400\n9.690193\n\n\n\n\n\nLooking at the levels of diabetes for each label within a variable turned out to be very interesting! Diabetes visually appears to be normally distributed across ages. At a glance, perhaps diabetes is more common in Males (about ~3% more in our observed data). The most interesting two variable I’d especially like to investigate further are education and Income. As education level increases the amount of diabetic cases appears decrease! Those who completed some high school showed about ~24% had diabetes, while of the college graduates only ~10% had diabetes. Further, the proportion of those with diabetic outcomes appears to decrease as income increases as well!\nWe will continue with modeling to see how levels of Education, Income, and Sex perform as predictors of Diabetic outcomes.\nClick here for the Modeling Page"
  }
]